{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheffjiu/pytorch-tutorials-zh/blob/main/saveloadrun_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTX3oqlv_YZs"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsE5-omp_YZt"
      },
      "source": [
        "[Learn the Basics](https://github.com/cheffjiu/pytorch-tutorials-zh/blob/main/intro.ipynb) \\|\\|\n",
        "[Quickstart](https://github.com/cheffjiu/pytorch-tutorials-zh/blob/main/quickstart_tutorial.ipynb) \\|\\|\n",
        "[Tensors](https://github.com/cheffjiu/pytorch-tutorials-zh/blob/main/tensorqs_tutorial.ipynb) \\|\\| [Datasets &\n",
        "DataLoaders](https://github.com/cheffjiu/pytorch-tutorials-zh/blob/main/data_tutorial.ipynb) \\|\\|\n",
        "[Transforms](https://github.com/cheffjiu/pytorch-tutorials-zh/blob/main/transforms_tutorial.ipynb) \\|\\| [Build\n",
        "Model](https://github.com/cheffjiu/pytorch-tutorials-zh/blob/main/buildmodel_tutorial.ipynb) \\|\\|\n",
        "[Autograd](https://github.com/cheffjiu/pytorch-tutorials-zh/blob/main/autogradqs_tutorial.ipynb) \\|\\|\n",
        "[Optimization](https://github.com/cheffjiu/pytorch-tutorials-zh/blob/main/optimization_tutorial.ipynb) \\|\\| **Save & Load Model**\n",
        "\n",
        "Save and Load the Model（保存加载模型）\n",
        "=======================\n",
        "\n",
        "在本节中，我们将了解如何通过保存、加载和运行模型预测来持久化模型状态。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqT6mNLt_YZu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y106K01S_YZu"
      },
      "source": [
        "Saving and Loading Model Weights（保存和加载模型权重）\n",
        "================================\n",
        "\n",
        "PyTorch模型将学习到的参数存储在一个内部状态字典中，这个字典被称为`state_dict`。可以通过`torch.save`方法来持久化这些参数："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zv_mqjl2_YZu"
      },
      "outputs": [],
      "source": [
        "model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0qPNUUr_YZv"
      },
      "source": [
        "要加载模型权重，你首先需要创建相同模型的一个实例，然后使用`load_state_dict()`方法加载参数。\n",
        "\n",
        "在下面的代码中，我们设置`weights_only=True`，将反序列化过程中执行的函数限制为仅加载权重所需的函数。在加载权重时，使用`weights_only=True`被视为最佳实践。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLYQSJgA_YZv"
      },
      "outputs": [],
      "source": [
        "model = models.vgg16() # we do not specify ``weights``, i.e. create untrained model\n",
        "model.load_state_dict(torch.load('model_weights.pth', weights_only=True))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WshVfQS8_YZv"
      },
      "source": [
        "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
        "\n",
        "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
        "\n",
        "<p>在进行推理之前，务必调用<code>model.eval()</code>方法，将随机失活（dropout）层和批归一化（batch normalization）层设置为评估模式。不这样做会导致推理结果不一致。</p>\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VerboVEW_YZv"
      },
      "source": [
        "Saving and Loading Models with Shapes（保存和加载带结构的模型）\n",
        "=====================================\n",
        "\n",
        "加载模型权重时，我们需要首先实例化模型类，因为该类定义了网络的结构。我们可能希望将此类的结构与模型一起保存，在这种情况下，我们可以将`model`（而不是`model.state_dict()`）传递给保存函数："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEuvt6HY_YZv"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfveM-hi_YZv"
      },
      "source": [
        "然后，我们可以按照以下演示加载模型。\n",
        "\n",
        "正如在[保存和加载torch.nn模块](https://pytorch.org/docs/main/notes/serialization.html#saving-and-loading-torch-nn-modules)中所述，保存`state_dict`被认为是最佳实践。但是，下面我们使用`weights_only=False`，因为这涉及到加载模型，这是`torch.save`的一个传统用例。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QL_O4m9_YZv"
      },
      "outputs": [],
      "source": [
        "model = torch.load('model.pth', weights_only=False),"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noJkC9GS_YZw"
      },
      "source": [
        "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
        "\n",
        "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
        "\n",
        "<p>这种方法在序列化模型时使用Python的<a href=\"https://docs.python.org/3/library/pickle.html\">pickle</a>模块，因此在加载模型时，它依赖于实际的类定义可用。</p>\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC26JBS9_YZw"
      },
      "source": [
        "Related Tutorials\n",
        "=================\n",
        "\n",
        "-   [Saving and Loading a General Checkpoint in\n",
        "    PyTorch](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html)\n",
        "-   [Tips for loading an nn.Module from a\n",
        "    checkpoint](https://pytorch.org/tutorials/recipes/recipes/module_load_state_dict_tips.html?highlight=loading%20nn%20module%20from%20checkpoint)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}